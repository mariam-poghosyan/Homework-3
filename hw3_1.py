# -*- coding: utf-8 -*-
"""hw3#1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MEcNur1bEHkkvxZxLoiK7mMRe9fDNPiW
"""

!pip install scrapy
import re
import time
import requests
import numpy as np
import pandas as pd
from scrapy.http import TextResponse

url = "http://books.toscrape.com/"
base_url = "http://books.toscrape.com/"

class Books:
    def __init__(self,url):
        self.url = url
        self.page = requests.get(self.url)
        self.response = TextResponse(body=self.page.text,url=self.url,encoding="utf-8")

    def get_next(self):
        next_url = self.response.css("li.next a::attr(href)").extract()
        return next_url

    def get_title(self):
        title = self.response.css('article[class="product_pod"] h3 a::attr(title)').extract();
        return title

    def get_rating(self):
        rating = self.response.css('p[class*="star-rating"]::attr(class)').extract()
        rating = [i.replace('star-rating','').strip() for i in rating]
        return rating 

    def get_price(self):
        price = self.response.css(".price_color::text").extract()
        price = [i.replace('Â£','') for i in price]
        return price 

    def get_book_url(self):
         book_url = [base_url+i for i in self.response.css('article[class="product_pod"] h3 a::attr(href)').extract()]
         return book_url

    def get_img_url(self):
        img_url = [base_url+i for i in self.response.css('.thumbnail::attr(src)').extract()]
        return img_url

    def get_instock(self):
        in_stock = self.response.css('.instock::text').extract()
        in_stock = [i.replace('\n','').strip() for i in in_stock]
        return in_stock[1::2]

    def get_genre(self):
        book_genre = self.response.css('.breadcrumb li:nth-child(3) a::text').extract()
        return(book_genre)

    def get_desc(self):
        book_desc = self.response.xpath('//article/p/text()').extract()
        return book_desc

bks = Books(url)
titles = []
ratings = []
prices = []
book_urls =[]
img_urls =[]
in_stock = []
genres = []
descriptions = []
desc = []
books = []

while True:
    if(bks.get_next() == []):
        titles = titles + bks.get_title()
        ratings = ratings + bks.get_rating()
        prices = prices + bks.get_price()
        book_urls = book_urls + bks.get_book_url()
        img_urls = img_urls + bks.get_img_url()
        in_stock = in_stock + bks.get_instock()
        break
    else:
        titles = titles + bks.get_title()
        ratings = ratings + bks.get_rating()
        prices = prices + bks.get_price()
        book_urls = book_urls + bks.get_book_url()
        img_urls = img_urls + bks.get_img_url()
        in_stock = in_stock + bks.get_instock()
        u = bks.get_next()[0].replace('catalogue/','')
        url = base_url + 'catalogue/' + u
        bks = Books(url)

for i in book_urls:
    if('catalogue/' not in i):
        index = str(i).index(base_url) + len(base_url)
        i = i[:index] + 'catalogue/' + i[index:]
    bks = Books(i)
    genres = genres + bks.get_genre()
    for k in bks.get_desc():
        desc.append(str(k).strip().strip('\n'))

descriptions = [i for i in desc if len(i)>0]

books.append(titles)
books.append(ratings)
books.append(prices)
books.append(book_urls)
books.append(img_urls)
books.append(in_stock)
books.append(genres)
books.append(descriptions)

books = list(map(list, zip(*books)))
books_df = pd.DataFrame(books, columns=['Titles','Ratings','Prices','Book link','Image link','Availability','Genre','Description'])

from google.colab import files
books_df.to_csv('problem1.csv')
files.download('problem1.csv')

price_average = sum(map(float,prices))/len(prices)

print(price_average)

#The average price is about $35.07.

books_df.sort_values(by = ["Prices"],ascending = False).head(10)

#The most expensive book is The Perfect Play and its genre is Romance. 
#We can not say that the most expensive books also have the highest rating.

jobs.append(vacancies)
jobs.append(companies)
jobs.append(deadlines)
jobs.append(locations)
jobs.append(i_pages)

jobs = list(map(list, zip(*jobs)))
jobs_df = pd.DataFrame(jobs, columns=['Vacancies','Companies','Deadlines','Locations','Individual Pages'])